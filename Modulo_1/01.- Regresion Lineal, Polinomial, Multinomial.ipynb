{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe1d9242",
   "metadata": {},
   "source": [
    "<img style=\"float: left;;\" src='Figures/alinco.png' /></a>\n",
    "\n",
    "\n",
    "# <center> <font color= #000047>  Módulo 1: Regresion Lineal, Multiple y Polinomial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53a8eab",
   "metadata": {},
   "source": [
    "## Regresión Lineal\n",
    "Consideremos un polinomio de grado uno:\n",
    "\n",
    "$$y = \\beta_1 x + \\beta_0.$$\n",
    "\n",
    "Esta es una **línea recta** que tiene pendiente $\\beta_1$. Sabemos que habrá una línea conectando dos puntos cualesquiera. Por tanto, *una ecuación polinómica de primer grado es un ajuste perfecto entre dos puntos*.\n",
    "\n",
    "Si consideramos ahora un polinomio de segundo grado,\n",
    "\n",
    "$$y = \\beta_2 x^2 + \\beta_1 x + \\beta_0,$$\n",
    "\n",
    "este se ajustará exactamente a tres puntos. Si aumentamos el grado de la función a la de un polinomio de tercer grado, obtenemos:\n",
    "\n",
    "$$y = \\beta_3 x^3 + \\beta_2 x^2 + \\beta_1 x + \\beta_0,$$\n",
    "\n",
    "que se ajustará a cuatro puntos.\n",
    "\n",
    "**Ejemplos**\n",
    "1. Encontrar la línea recta que pasa exactamente por los puntos $(0,1)$ y $(1,0)$.\n",
    "2. Encontrar la parábola que pasa exactamente por los puntos $(-1,1)$, $(0,0)$ y $(1,1)$.\n",
    "\n",
    "**Solución**\n",
    "1. Consideramos $y=\\beta_1 x + \\beta_0$. Evaluando en el punto $(0,1)$, obtenemos $\\beta_1(0) + \\beta_0 = 1$. Ahora, evaluando en el punto $(1,0)$, obtenemos $\\beta_1(1) + \\beta_0 = 0$. De esta manera,\n",
    "$$\\left[\\begin{array}{cc} 1 & 0 \\\\ 1 & 1\\end{array}\\right]\\left[\\begin{array}{c} \\beta_0 \\\\ \\beta_1\\end{array}\\right]=\\left[\\begin{array}{c} 1 \\\\ 0\\end{array}\\right].$$\n",
    "Resolviendo, $\\beta_0=-\\beta_1=1$.\n",
    "\n",
    "2. Consideramos $y=\\beta_2 x^2 + \\beta_1 x + \\beta_0$. Evaluando en el punto $(-1,1)$, obtenemos $\\beta_2(-1)^2 + \\beta_1(-1) + \\beta_0 = 1$. Ahora, evaluando en el punto $(0,0)$, obtenemos $\\beta_2(0)^2 + \\beta_1(0) + \\beta_0 = 0$. Finalmente, evaluando en el punto $(1,1)$, obtenemos $\\beta_2(1)^2 + \\beta_1(1) + \\beta_0 = 1$. De esta manera,\n",
    "$$\\left[\\begin{array}{ccc} 1 & -1 & 1 \\\\ 1 & 0 & 0 \\\\ 1 & 1 & 1 \\end{array}\\right]\\left[\\begin{array}{c} \\beta_0 \\\\ \\beta_1 \\\\ \\beta_2 \\end{array}\\right]=\\left[\\begin{array}{c} 1 \\\\ 0 \\\\ 1 \\end{array}\\right].$$\n",
    "Resolviendo, $\\beta_0=\\beta_1=0$ y $\\beta_2=1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441a82dd",
   "metadata": {},
   "source": [
    "### ¿Qué tienen en común los anteriores problemas?\n",
    "Las curvas están completamente determinadas por los puntos (datos limpios, suficientes y necesarios).\n",
    "\n",
    "Esto se traduce en que, al llevar el problema a un sistema de ecuaciones lineales, existe una única solución: **no hay necesidad, ni se puede optimizar nada**.\n",
    "\n",
    "La realidad es que los datos que encontraremos en nuestra vida profesional se parecen más a esto..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe5ce1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daaf2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "X, y = datasets.make_regression(n_samples=100, n_features=1, noise=20, random_state=4, bias=50)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(X[:,0],y, color='b', marker='o', s=30)\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$y$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f12b9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc590ed9",
   "metadata": {},
   "source": [
    "### ¿Cómo ajustamos una curva a esto?\n",
    "\n",
    "Consideramos entonces ajustes de la forma \n",
    "\n",
    "$$\\hat{f}(x) = \\beta_0+\\beta_1 x = \\left[1 \\quad x\\right]\\left[\\begin{array}{c} \\beta_0 \\\\ \\beta_1 \\end{array}\\right]=\\left[1 \\quad x\\right]\\boldsymbol{\\beta}$$ (lineas rectas).\n",
    "\n",
    "\n",
    "Para decir '*mejor*', tenemos que definir algún sentido en que una recta se ajuste *mejor* que otra.\n",
    "\n",
    "> El objetivo es seleccionar los coeficientes $\\boldsymbol{\\beta}=\\left[\\beta_0 \\quad \\beta_1 \\right]^T$, de forma que la función evaluada en los puntos $x_i$ ($\\hat{f}(x_i)$) aproxime los valores correspondientes $y_i$.\n",
    "\n",
    "> El objetivo es encontrar los $\\boldsymbol{\\beta}=\\left[\\beta_0 \\quad \\beta_1 \\right]^T$ que minimiza El error cuadrático medio (MSE):\n",
    "$$\\frac{1}{2n}\\sum_{i=1}^{n}(y_i-\\hat{f}(x_i))^2=\\frac{1}{2n}\\sum_{i=1}^{n}(y_i-(\\beta_0+ \\beta_1x_i))^2=\\frac{1}{2n}\\sum_{i=1}^{n}(y_i-\\left[1 \\quad x_i\\right]\\boldsymbol{\\beta})^2=\\frac{1}{2n}\\left|\\left|\\boldsymbol{y}-\\boldsymbol{X}\\boldsymbol{\\beta}\\right|\\right|^2,$$\n",
    "\n",
    "donde $\\boldsymbol{y}=\\left[y_1\\quad\\dots\\quad y_n\\right]^T$, y $\\boldsymbol{X}=\\left[\\begin{array}{ccc}1 & x_1\\\\ \\vdots & \\vdots \\\\ 1 & x_n\\end{array}\\right].$ \n",
    "\n",
    "## Gradiente Descendente\n",
    "\n",
    "Partiendo del **MSE**:\n",
    "\n",
    "$$ J(\\beta) = \\frac{1}{2m}\\sum_{i=1}^m (\\hat{y}(x_i) - y_i)^2$$  \n",
    "\n",
    "$\\beta = [\\beta_0, \\beta_1]$\n",
    "\n",
    "\n",
    "El algoritmo de gradiente descendente es un método de optimización local en el que, en cada paso, empleamos el gradiente negativo como dirección de descenso. \n",
    "\n",
    "$$\\boldsymbol{\\beta}_{k} = \\boldsymbol{\\beta}_{k-1}\\nabla J(\\boldsymbol{\\beta}_{k-1})$$\n",
    "\n",
    "Para una regresión lineal tendríamos que las ecuaciones del algoritmo de gradiente descendente son:\n",
    "\n",
    "\n",
    "$$ \\nabla J(\\boldsymbol{\\beta}) = \\left[\\begin{array}{c} \\frac{1}{m} \\sum_{i=1}^m (\\hat{y}(x_i) - y_i) \\\\ \n",
    "\\frac{1}{m} \\sum_{i=1}^m (\\hat{y}(x_i) - y_i)x_i\\end{array}\\right].$$\n",
    "\n",
    "\n",
    "$$ \\beta_0 = \\beta_0 - \\alpha \\frac{1}{m} \\sum_{i=1}^m (\\hat{y}(x_i) - y_i)$$\n",
    "\n",
    "$$ \\beta_1 = \\beta_1 - \\alpha \\frac{1}{m} \\sum_{i=1}^m (\\hat{y}(x_i) - y_i)x_i$$\n",
    "\n",
    "<img alt=\"Datos categóricos con Python\" title=\"GradientDescendt\" src=\"https://cdn-images-1.medium.com/max/1600/0*fU8XFt-NCMZGAWND.\" high=300px, width=300px>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c707ba97",
   "metadata": {},
   "source": [
    "## Linear Regression Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf626df2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "797fb2b0",
   "metadata": {},
   "source": [
    "## Train-Test-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b873c213",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28f403f0",
   "metadata": {},
   "source": [
    "### Ejemplo 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc27fa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar de la Librería LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d6164d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar un Modelo de regresión Lineal\n",
    "\n",
    "#1.- Entrenamiento del modeloreg_model = LinearRegression()\n",
    "\n",
    "\n",
    "#2.- Predecir los valores de x\n",
    "\n",
    "\n",
    "#3.- Graficar el modelo con los datos\n",
    "\n",
    "#4.- Evaluar el modelo : \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7b323c",
   "metadata": {},
   "source": [
    "## Regression Polinomial "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f468e3",
   "metadata": {},
   "source": [
    "Ahora, la ecuación para la Regresión Polinomial será la siguiente:\n",
    "\n",
    "$$y =  \\beta_0 + \\beta_1 x + \\beta_2 x^2 + ... + \\beta_n x^n$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c9baee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c8d3201",
   "metadata": {},
   "source": [
    "## Regression Multiple "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec877f0",
   "metadata": {},
   "source": [
    "$$y =  \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + ... + \\beta_n x_n$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbb8ac4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c60568",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "889cd8a0",
   "metadata": {},
   "source": [
    "## Actividad:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11598df",
   "metadata": {},
   "source": [
    "Considere el dataset \"real_state.csv\" que se encuentra en la carpeta de Data, realice un Análisis Exploratorio de Datos. En base a lo obtenido seleccione una variable a predecir ($y$) y un conjunto de variables para entrenar ($X$) un modelo de regresión lineal. Utilice la librería de la clase, después compare sus resultados con un modelo de regresion lineal creado mediante la librería sklearn.\n",
    "\n",
    "> Programe la métrica r2_score y mse en su librería, estas métricas sirven para medir el rendimiento de los modelos de regresión.\n",
    "\n",
    "> Utilice las métricas mean_squared_error y r2_score para evaluar el modelo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632214cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
